{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading https://files.pythonhosted.org/packages/00/37/a392e669a83fef72b916009c438a924d2a9d70bc8aea62662b207105ed98/lightgbm-2.2.3-py2.py3-none-win_amd64.whl (515kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.14.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.2.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리를 완료하여 저장된 데이터를 읽어서 다양한 모델을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 373 entries, 0 to 372\n",
      "Data columns (total 15 columns):\n",
      "Subject ID    373 non-null int64\n",
      "MRI ID        373 non-null int64\n",
      "Group         373 non-null int64\n",
      "Visit         373 non-null int64\n",
      "MR Delay      373 non-null int64\n",
      "M/F           373 non-null int64\n",
      "Hand          373 non-null int64\n",
      "Age           373 non-null int64\n",
      "EDUC          373 non-null int64\n",
      "SES           373 non-null int64\n",
      "MMSE          373 non-null int64\n",
      "CDR           373 non-null int64\n",
      "eTIV          373 non-null int64\n",
      "nWBV          373 non-null int64\n",
      "ASF           373 non-null int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 43.8 KB\n"
     ]
    }
   ],
   "source": [
    "datafilename = \"data/oasis_longitudinal_processed.csv\"\n",
    "\n",
    "existfile = os.path.isfile(datafilename)\n",
    "if existfile :\n",
    "    df = pd.read_csv(datafilename, header=0, encoding='utf-8')\n",
    "else :\n",
    "    print(\"파일 '{}'가 존재하지 않습니다. 확인 후 진행해주세요\".format(datafilename))\n",
    "    \n",
    "# print the concise summery of the dataset\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링을 위한 변수 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링을 위한 변수 선택\n",
    "feature_col_names = [\"M/F\", \"Age\", \"EDUC\", \"SES\", \"MMSE\", \"eTIV\", \"nWBV\", \"ASF\"]\n",
    "predicted_class_names = ['Group']\n",
    "\n",
    "X = df[feature_col_names].values\n",
    "y = df[predicted_class_names].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count : 373, df_train count : 261, df_test count : 112\n"
     ]
    }
   ],
   "source": [
    "# train, test set 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "print(\"total count : {}, df_train count : {}, df_test count : {}\".format(len(df), len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다양한 모델을 사용한 코드 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Logistic Regression \n",
    "- Logistic Regression을 sklearn 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : Logistic Regression ===\n",
      "Accuracy Score : 0.7410714285714286\n",
      "AUC Score : 0.742948717948718\n",
      "<Confusion Matrix>\n",
      "[[40 12]\n",
      " [17 43]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.77      0.73        52\n",
      "          1       0.78      0.72      0.75        60\n",
      "\n",
      "avg / total       0.74      0.74      0.74       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(penalty='l2', C=10.0)\n",
    "LR = LR.fit(X_train, y_train.ravel())\n",
    "y_test_pred = LR.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : Logistic Regression ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1.0, 10.0,100.0]\n",
    "}\n",
    "gridsearch = GridSearchCV(estimator=LogisticRegression(random_state=1234), param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "gridsearch.fit(X_train, y_train.ravel())     \n",
    "\n",
    "print(gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-NN (k-Nearest Neighbors)\n",
    "- k Neighbors Classifier 를 sklearn 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성, 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : k-Nearerst Neighbors Classifier ===\n",
      "Accuracy Score : 0.6607142857142857\n",
      "AUC Score : 0.6666666666666666\n",
      "<Confusion Matrix>\n",
      "[[39 13]\n",
      " [25 35]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.75      0.67        52\n",
      "          1       0.73      0.58      0.65        60\n",
      "\n",
      "avg / total       0.67      0.66      0.66       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "KNN = KNN.fit(X_train, y_train.ravel())\n",
    "y_test_pred = KNN.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : k-Nearerst Neighbors Classifier ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier\n",
    "- Decision Tree Classifier 를 sklearn 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성, 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : Decision Tree Classifier ===\n",
      "Accuracy Score : 0.7589285714285714\n",
      "AUC Score : 0.7583333333333333\n",
      "<Confusion Matrix>\n",
      "[[39 13]\n",
      " [14 46]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.75      0.74        52\n",
      "          1       0.78      0.77      0.77        60\n",
      "\n",
      "avg / total       0.76      0.76      0.76       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DTC = DecisionTreeClassifier(criterion='gini',\n",
    "                             max_features=None, \n",
    "                             max_depth=None,\n",
    "                             min_samples_split=2,\n",
    "                             min_samples_leaf=1)\n",
    "DTC = DTC.fit(X_train, y_train.ravel())\n",
    "y_test_pred = DTC.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : Decision Tree Classifier ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forrest Classifier\n",
    "- Random Forrest Classifier 를 sklearn 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성, 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : Random Forrest Classifier ===\n",
      "Accuracy Score : 0.8482142857142857\n",
      "AUC Score : 0.8506410256410255\n",
      "<Confusion Matrix>\n",
      "[[46  6]\n",
      " [11 49]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.84        52\n",
      "          1       0.89      0.82      0.85        60\n",
      "\n",
      "avg / total       0.85      0.85      0.85       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RC = RandomForestClassifier(n_estimators=100, max_features=3)\n",
    "RC = RC.fit(X_train, y_train.ravel())\n",
    "y_test_pred = RC.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : Random Forrest Classifier ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'n_estimators': 45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    6.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "    'max_features': ['auto', 'log2']\n",
    "}\n",
    "gridsearch = GridSearchCV(estimator=RandomForestClassifier(random_state=1234), param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "gridsearch.fit(X_train, y_train.ravel())     \n",
    "\n",
    "print(gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier\n",
    "- Gradient Boosting Classifier 를 sklearn 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성, 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : Gradient Boosting Classifier ===\n",
      "Accuracy Score : 0.8392857142857143\n",
      "AUC Score : 0.8384615384615384\n",
      "<Confusion Matrix>\n",
      "[[43  9]\n",
      " [ 9 51]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83        52\n",
      "          1       0.85      0.85      0.85        60\n",
      "\n",
      "avg / total       0.84      0.84      0.84       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBC = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                 max_features=3,\n",
    "                                 subsample=0.5,\n",
    "                                 n_estimators=200)\n",
    "GBC = GBC.fit(X_train, y_train.ravel())\n",
    "y_test_pred = GBC.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : Gradient Boosting Classifier ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XgBoost Classifier\n",
    "- XgBoost Classifier 를 xgnoost 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성, 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : Xgboost Classifier ===\n",
      "Accuracy Score : 0.8214285714285714\n",
      "AUC Score : 0.8179487179487179\n",
      "<Confusion Matrix>\n",
      "[[40 12]\n",
      " [ 8 52]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.77      0.80        52\n",
      "          1       0.81      0.87      0.84        60\n",
      "\n",
      "avg / total       0.82      0.82      0.82       112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGB = XGBClassifier(learning_rate=0.1,\n",
    "                    max_features=3,\n",
    "                    subsample=0.5,\n",
    "                    n_estimators=200)\n",
    "XGB = XGB.fit(X_train, y_train.ravel())\n",
    "y_test_pred = XGB.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : Xgboost Classifier ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM (Support Vector Machine)\n",
    "- Linear SVM Classifier 를 sklearn 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성, 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : Linear SVC ===\n",
      "Accuracy Score : 0.5357142857142857\n",
      "AUC Score : 0.5\n",
      "<Confusion Matrix>\n",
      "[[ 0 52]\n",
      " [ 0 60]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        52\n",
      "          1       0.54      1.00      0.70        60\n",
      "\n",
      "avg / total       0.29      0.54      0.37       112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "LinSVC = LinearSVC(penalty='l2', C=10.0)\n",
    "LinSVC = LinSVC.fit(X_train, y_train.ravel())\n",
    "y_test_pred = LinSVC.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : Linear SVC ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-linear SVM (Support Vector Machine)\n",
    "- Non-linear SVM Classifier 를 sklearn 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성, 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : Non-linear SVC ===\n",
      "Accuracy Score : 0.4642857142857143\n",
      "AUC Score : 0.5\n",
      "<Confusion Matrix>\n",
      "[[52  0]\n",
      " [60  0]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      1.00      0.63        52\n",
      "          1       0.00      0.00      0.00        60\n",
      "\n",
      "avg / total       0.22      0.46      0.29       112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "rbfSVC = SVC(kernel='rbf', gamma=1.0, C=10.0)\n",
    "rbfSVC = rbfSVC.fit(X_train, y_train.ravel())\n",
    "y_test_pred = rbfSVC.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : Non-linear SVC ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifier\n",
    "- Voting Classifier 를 sklearn 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성, 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : Voting Classifier ===\n",
      "Accuracy Score : 0.8303571428571429\n",
      "AUC Score : 0.8326923076923077\n",
      "<Confusion Matrix>\n",
      "[[45  7]\n",
      " [12 48]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.87      0.83        52\n",
      "          1       0.87      0.80      0.83        60\n",
      "\n",
      "avg / total       0.83      0.83      0.83       112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "vote_est = [('etc', ExtraTreesClassifier()),\n",
    "            ('gb', GradientBoostingClassifier()),\n",
    "            ('abc', AdaBoostClassifier()),\n",
    "            ('rfc', RandomForestClassifier(criterion='gini', max_depth=8, max_features='auto', n_estimators=200)),\n",
    "            ('svc', SVC(probability=True)),\n",
    "            ('xgb', XGBClassifier())\n",
    "#            ('lgbm', LGBMClassifier())\n",
    "           ]\n",
    "\n",
    "vClf = VotingClassifier(estimators=vote_est, voting='hard')\n",
    "vClf = vClf.fit(X_train, y_train.ravel())\n",
    "y_test_pred = vClf.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : Voting Classifier ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTrees Classifier\n",
    "- ExtraTrees Classifier 를 sklearn 으로 부터 불러 들임 (import)\n",
    "- 클래스의 인스턴스 생성, 및 하이퍼 파라미터 세팅\n",
    "- 적합 (fit) 및 예측(predict) 함수 실행\n",
    "- 교차 검증 (cross-validation) 방법을 사용하여 최적의 하이퍼 파라미터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modeling : ExtraTrees Classifier ===\n",
      "Accuracy Score : 0.8392857142857143\n",
      "AUC Score : 0.841025641025641\n",
      "<Confusion Matrix>\n",
      "[[45  7]\n",
      " [11 49]]\n",
      "<Classiffication Report>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.87      0.83        52\n",
      "          1       0.88      0.82      0.84        60\n",
      "\n",
      "avg / total       0.84      0.84      0.84       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etClf = ExtraTreesClassifier(n_estimators=100, max_features=8)\n",
    "etClf = etClf.fit(X_train, y_train.ravel())\n",
    "y_test_pred = etClf.predict(X_test)\n",
    "\n",
    "print('\\n=== Modeling : ExtraTrees Classifier ===')\n",
    "print('Accuracy Score : {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('AUC Score : {}'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "print('<Confusion Matrix>')\n",
    "print(metrics.confusion_matrix(y_test, y_test_pred))\n",
    "print('<Classiffication Report>')\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
